{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                  # A fundamental package for linear algebra and multidimensional arrays\n",
    "import numpy as np                   # Data analysis and data manipulating tool\n",
    "import random                        # Library to generate random numbers\n",
    "from collections import Counter      # Collection is a Python module that implements specialized container datatypes providing\n",
    "                                     # alternatives to Python’s general purpose built-in containers, dict, list, set, and tuple.\n",
    "                                     # Counter is a dict subclass for counting hashable objects\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To ignore warnings in the notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a subset of the original data available at kaggle.\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Polar\\\\Documents\\\\ESCUELA\\\\5TO_SEMESTRE\\\\MAKINITAS\\\\practica6\\\\iris\\\\iris.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Leave-One-Out Cross-Validation: 0.92\n",
      "Matriz de Confusión Leave-One-Out:\n",
      "[[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  7 43]]\n",
      "Precisión de Hold-Out Validation (70-30): 0.96\n",
      "Matriz de Confusión Hold-Out:\n",
      "[[19  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  0 13]]\n",
      "Precisión de 10-Fold Cross-Validation Estratificado: 0.92\n",
      "Matriz de Confusión 10-Fold Cross-Validation:\n",
      "[[20 16 14]\n",
      " [15 20 15]\n",
      " [15 16 19]]\n"
     ]
    }
   ],
   "source": [
    "# Codificar la columna 'class' como valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "data['class'] = label_encoder.fit_transform(data['class'])\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = data.drop(columns=['class']).values\n",
    "y = data['class'].values\n",
    "\n",
    "# Función para calcular la distancia Euclidiana\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Función para clasificar un nuevo punto usando el algoritmo de distancia mínima\n",
    "def classify_min_distance(new_point, centroids):\n",
    "    min_distance = float('inf')\n",
    "    closest_class = None\n",
    "    \n",
    "    for species, centroid in centroids.iterrows():\n",
    "        distance = euclidean_distance(new_point, centroid)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_class = species\n",
    "    return closest_class\n",
    "\n",
    "# --- Leave-One-Out Cross-Validation ---\n",
    "loo = LeaveOneOut()\n",
    "correct_predictions_loo = 0\n",
    "y_pred_loo = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # Dividir datos en entrenamiento y prueba\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Calcular centroides con los datos de entrenamiento\n",
    "    train_data = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "    train_data['class'] = y_train\n",
    "    centroids = train_data.groupby('class').mean()\n",
    "    \n",
    "    # Clasificar el punto de prueba\n",
    "    predicted_class = classify_min_distance(X_test[0], centroids)\n",
    "    y_pred_loo.append(predicted_class)\n",
    "    \n",
    "    # Comparar con la clase real\n",
    "    if predicted_class == y_test[0]:\n",
    "        correct_predictions_loo += 1\n",
    "\n",
    "# Calcular y mostrar la precisión de Leave-One-Out\n",
    "accuracy_loo = correct_predictions_loo / len(X)\n",
    "print(f\"Precisión de Leave-One-Out Cross-Validation: {accuracy_loo:.2f}\")\n",
    "\n",
    "# Imprimir la matriz de confusión para Leave-One-Out\n",
    "print(\"Matriz de Confusión Leave-One-Out:\")\n",
    "print(confusion_matrix(y, y_pred_loo))\n",
    "\n",
    "# --- Hold-Out Validation (70-30 split) ---\n",
    "# Dividir en entrenamiento y prueba con un 70-30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Calcular centroides con el conjunto de entrenamiento\n",
    "train_data = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "train_data['class'] = y_train\n",
    "centroids = train_data.groupby('class').mean()\n",
    "\n",
    "# Validar en el conjunto de prueba\n",
    "correct_predictions_holdout = 0\n",
    "y_pred_holdout = []\n",
    "\n",
    "for i, test_point in enumerate(X_test):\n",
    "    predicted_class = classify_min_distance(test_point, centroids)\n",
    "    y_pred_holdout.append(predicted_class)\n",
    "    if predicted_class == y_test[i]:\n",
    "        correct_predictions_holdout += 1\n",
    "\n",
    "# Calcular y mostrar la precisión de Hold-Out\n",
    "accuracy_holdout = correct_predictions_holdout / len(X_test)\n",
    "print(f\"Precisión de Hold-Out Validation (70-30): {accuracy_holdout:.2f}\")\n",
    "\n",
    "# Imprimir la matriz de confusión para Hold-Out\n",
    "print(\"Matriz de Confusión Hold-Out:\")\n",
    "print(confusion_matrix(y_test, y_pred_holdout))\n",
    "\n",
    "# --- 10-Fold Cross-Validation Estratificado ---\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "correct_predictions_kfold = 0\n",
    "total_test_samples = 0\n",
    "y_pred_kfold = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Dividir datos en entrenamiento y prueba para el fold actual\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Calcular centroides con los datos de entrenamiento del fold actual\n",
    "    train_data = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "    train_data['class'] = y_train\n",
    "    centroids = train_data.groupby('class').mean()\n",
    "    \n",
    "    # Validar en el conjunto de prueba\n",
    "    for i, test_point in enumerate(X_test):\n",
    "        predicted_class = classify_min_distance(test_point, centroids)\n",
    "        y_pred_kfold.append(predicted_class)\n",
    "        if predicted_class == y_test[i]:\n",
    "            correct_predictions_kfold += 1\n",
    "    \n",
    "    # Actualizar el conteo de muestras de prueba\n",
    "    total_test_samples += len(X_test)\n",
    "\n",
    "# Calcular y mostrar la precisión de 10-Fold Cross-Validation\n",
    "accuracy_kfold = correct_predictions_kfold / total_test_samples\n",
    "print(f\"Precisión de 10-Fold Cross-Validation Estratificado: {accuracy_kfold:.2f}\")\n",
    "\n",
    "# Imprimir la matriz de confusión para 10-Fold Cross-Validation\n",
    "print(\"Matriz de Confusión 10-Fold Cross-Validation:\")\n",
    "print(confusion_matrix(y, y_pred_kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# This is a subset of the original data available at kaggle.\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Polar\\\\Documents\\\\ESCUELA\\\\5TO_SEMESTRE\\\\MAKINITAS\\\\practica6\\\\winequality\\\\winequality-red.csv\", delimiter=\";\")\n",
    "\n",
    "data.head()\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Leave-One-Out Cross-Validation: 0.27\n",
      "Matriz de Confusión Leave-One-Out:\n",
      "[[  6   0   2   1   0   1]\n",
      " [ 28   0  15   5   2   3]\n",
      " [208  43 330  67  12  21]\n",
      " [254  32 190  97  24  41]\n",
      " [114   6  38  28   4   9]\n",
      " [ 11   0   4   1   1   1]]\n",
      "Precisión de Hold-Out Validation (70-30): 0.24\n",
      "Matriz de Confusión Hold-Out:\n",
      "[[ 1  0  0  0  0  0]\n",
      " [10  1  2  1  0  3]\n",
      " [64 12 96  9  7  7]\n",
      " [75 19 58 17 16 15]\n",
      " [38  1 12  8  0  2]\n",
      " [ 3  0  2  0  0  1]]\n",
      "Precisión de 10-Fold Cross-Validation Estratificado: 0.28\n",
      "Matriz de Confusión 10-Fold Cross-Validation:\n",
      "[[  6   0   3   0   1   0]\n",
      " [ 23   2  14   8   2   4]\n",
      " [252  32 242  86  34  35]\n",
      " [241  39 227  79  26  26]\n",
      " [ 67   7  88  22   4  11]\n",
      " [  6   1   8   2   0   1]]\n"
     ]
    }
   ],
   "source": [
    "# Codificar la columna 'class' como valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "data['quality'] = label_encoder.fit_transform(data['quality'])\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = data.drop(columns=['quality']).values\n",
    "y = data['quality'].values\n",
    "\n",
    "# Función para calcular la distancia Euclidiana\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Función para clasificar un nuevo punto usando el algoritmo de distancia mínima\n",
    "def classify_min_distance(new_point, centroids):\n",
    "    min_distance = float('inf')\n",
    "    closest_class = None\n",
    "    \n",
    "    for species, centroid in centroids.iterrows():\n",
    "        distance = euclidean_distance(new_point, centroid)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_class = species\n",
    "    return closest_class\n",
    "\n",
    "# --- Leave-One-Out Cross-Validation ---\n",
    "loo = LeaveOneOut()\n",
    "correct_predictions_loo = 0\n",
    "y_pred_loo = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # Dividir datos en entrenamiento y prueba\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Calcular centroides con los datos de entrenamiento\n",
    "    train_data = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "    train_data['quality'] = y_train\n",
    "    centroids = train_data.groupby('quality').mean()\n",
    "    \n",
    "    # Clasificar el punto de prueba\n",
    "    predicted_class = classify_min_distance(X_test[0], centroids)\n",
    "    y_pred_loo.append(predicted_class)\n",
    "    \n",
    "    # Comparar con la clase real\n",
    "    if predicted_class == y_test[0]:\n",
    "        correct_predictions_loo += 1\n",
    "\n",
    "# Calcular y mostrar la precisión de Leave-One-Out\n",
    "accuracy_loo = correct_predictions_loo / len(X)\n",
    "print(f\"Precisión de Leave-One-Out Cross-Validation: {accuracy_loo:.2f}\")\n",
    "\n",
    "# Imprimir la matriz de confusión para Leave-One-Out\n",
    "print(\"Matriz de Confusión Leave-One-Out:\")\n",
    "print(confusion_matrix(y, y_pred_loo))\n",
    "\n",
    "# --- Hold-Out Validation (70-30 split) ---\n",
    "# Dividir en entrenamiento y prueba con un 70-30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Calcular centroides con el conjunto de entrenamiento\n",
    "train_data = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "train_data['quality'] = y_train\n",
    "centroids = train_data.groupby('quality').mean()\n",
    "\n",
    "# Validar en el conjunto de prueba\n",
    "correct_predictions_holdout = 0\n",
    "y_pred_holdout = []\n",
    "\n",
    "for i, test_point in enumerate(X_test):\n",
    "    predicted_class = classify_min_distance(test_point, centroids)\n",
    "    y_pred_holdout.append(predicted_class)\n",
    "    if predicted_class == y_test[i]:\n",
    "        correct_predictions_holdout += 1\n",
    "\n",
    "# Calcular y mostrar la precisión de Hold-Out\n",
    "accuracy_holdout = correct_predictions_holdout / len(X_test)\n",
    "print(f\"Precisión de Hold-Out Validation (70-30): {accuracy_holdout:.2f}\")\n",
    "\n",
    "# Imprimir la matriz de confusión para Hold-Out\n",
    "print(\"Matriz de Confusión Hold-Out:\")\n",
    "print(confusion_matrix(y_test, y_pred_holdout))\n",
    "\n",
    "# --- 10-Fold Cross-Validation Estratificado ---\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "correct_predictions_kfold = 0\n",
    "total_test_samples = 0\n",
    "y_pred_kfold = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Dividir datos en entrenamiento y prueba para el fold actual\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Calcular centroides con los datos de entrenamiento del fold actual\n",
    "    train_data = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "    train_data['quality'] = y_train\n",
    "    centroids = train_data.groupby('quality').mean()\n",
    "    \n",
    "    # Validar en el conjunto de prueba\n",
    "    for i, test_point in enumerate(X_test):\n",
    "        predicted_class = classify_min_distance(test_point, centroids)\n",
    "        y_pred_kfold.append(predicted_class)\n",
    "        if predicted_class == y_test[i]:\n",
    "            correct_predictions_kfold += 1\n",
    "    \n",
    "    # Actualizar el conteo de muestras de prueba\n",
    "    total_test_samples += len(X_test)\n",
    "\n",
    "# Calcular y mostrar la precisión de 10-Fold Cross-Validation\n",
    "accuracy_kfold = correct_predictions_kfold / total_test_samples\n",
    "print(f\"Precisión de 10-Fold Cross-Validation Estratificado: {accuracy_kfold:.2f}\")\n",
    "\n",
    "# Imprimir la matriz de confusión para 10-Fold Cross-Validation\n",
    "print(\"Matriz de Confusión 10-Fold Cross-Validation:\")\n",
    "print(confusion_matrix(y, y_pred_kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# This is a subset of the original data available at kaggle.\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Polar\\\\Documents\\\\ESCUELA\\\\5TO_SEMESTRE\\\\MAKINITAS\\\\practica6\\\\winequality\\\\winequality-white.csv\", delimiter=\";\")\n",
    "\n",
    "data.head()\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Leave-One-Out Cross-Validation: 0.10\n",
      "Matriz de Confusión Leave-One-Out:\n",
      "[[ 10   3   1   0   0   0   6]\n",
      " [ 40  34  17   3   0   1  68]\n",
      " [572 182 253 103  15  39 293]\n",
      " [607 228 284 169  58  99 753]\n",
      " [122  65 103  99  26  74 391]\n",
      " [ 24   8  27  10  11  17  78]\n",
      " [  0   2   0   1   0   1   1]]\n",
      "Precisión de Hold-Out Validation (70-30): 0.20\n",
      "Matriz de Confusión Hold-Out:\n",
      "[[  0   0   6   0   0   0   1]\n",
      " [  0   8  15   3   0   0  14]\n",
      " [ 13  56 235  22   7  13  80]\n",
      " [ 38  75 251  27  23  28 226]\n",
      " [ 22  22  74  15  16  18 113]\n",
      " [  2   5   7   1   3   3  28]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Precisión de 10-Fold Cross-Validation Estratificado: 0.12\n",
      "Matriz de Confusión 10-Fold Cross-Validation:\n",
      "[[  5   2   1   3   2   0   7]\n",
      " [ 45  28  26   5   6   6  47]\n",
      " [359 212 246 117  25  62 436]\n",
      " [548 263 385 167  56  99 680]\n",
      " [234  80 159  70  27  45 265]\n",
      " [ 36  16  34  16   6  11  56]\n",
      " [  0   0   0   0   1   1   3]]\n"
     ]
    }
   ],
   "source": [
    "# Codificar la columna 'class' como valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "data['quality'] = label_encoder.fit_transform(data['quality'])\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = data.drop(columns=['quality']).values\n",
    "y = data['quality'].values\n",
    "\n",
    "# Función para calcular la distancia Euclidiana\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Función para clasificar un nuevo punto usando el algoritmo de distancia mínima\n",
    "def classify_min_distance(new_point, centroids):\n",
    "    min_distance = float('inf')\n",
    "    closest_class = None\n",
    "    \n",
    "    for species, centroid in centroids.iterrows():\n",
    "        distance = euclidean_distance(new_point, centroid)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_class = species\n",
    "    return closest_class\n",
    "\n",
    "# --- Leave-One-Out Cross-Validation ---\n",
    "loo = LeaveOneOut()\n",
    "correct_predictions_loo = 0\n",
    "y_pred_loo = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # Dividir datos en entrenamiento y prueba\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Calcular centroides con los datos de entrenamiento\n",
    "    train_data = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "    train_data['quality'] = y_train\n",
    "    centroids = train_data.groupby('quality').mean()\n",
    "    \n",
    "    # Clasificar el punto de prueba\n",
    "    predicted_class = classify_min_distance(X_test[0], centroids)\n",
    "    y_pred_loo.append(predicted_class)\n",
    "    \n",
    "    # Comparar con la clase real\n",
    "    if predicted_class == y_test[0]:\n",
    "        correct_predictions_loo += 1\n",
    "\n",
    "# Calcular y mostrar la precisión de Leave-One-Out\n",
    "accuracy_loo = correct_predictions_loo / len(X)\n",
    "print(f\"Precisión de Leave-One-Out Cross-Validation: {accuracy_loo:.2f}\")\n",
    "\n",
    "# Imprimir la matriz de confusión para Leave-One-Out\n",
    "print(\"Matriz de Confusión Leave-One-Out:\")\n",
    "print(confusion_matrix(y, y_pred_loo))\n",
    "\n",
    "# --- Hold-Out Validation (70-30 split) ---\n",
    "# Dividir en entrenamiento y prueba con un 70-30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Calcular centroides con el conjunto de entrenamiento\n",
    "train_data = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "train_data['quality'] = y_train\n",
    "centroids = train_data.groupby('quality').mean()\n",
    "\n",
    "# Validar en el conjunto de prueba\n",
    "correct_predictions_holdout = 0\n",
    "y_pred_holdout = []\n",
    "\n",
    "for i, test_point in enumerate(X_test):\n",
    "    predicted_class = classify_min_distance(test_point, centroids)\n",
    "    y_pred_holdout.append(predicted_class)\n",
    "    if predicted_class == y_test[i]:\n",
    "        correct_predictions_holdout += 1\n",
    "\n",
    "# Calcular y mostrar la precisión de Hold-Out\n",
    "accuracy_holdout = correct_predictions_holdout / len(X_test)\n",
    "print(f\"Precisión de Hold-Out Validation (70-30): {accuracy_holdout:.2f}\")\n",
    "\n",
    "# Imprimir la matriz de confusión para Hold-Out\n",
    "print(\"Matriz de Confusión Hold-Out:\")\n",
    "print(confusion_matrix(y_test, y_pred_holdout))\n",
    "\n",
    "# --- 10-Fold Cross-Validation Estratificado ---\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "correct_predictions_kfold = 0\n",
    "total_test_samples = 0\n",
    "y_pred_kfold = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Dividir datos en entrenamiento y prueba para el fold actual\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Calcular centroides con los datos de entrenamiento del fold actual\n",
    "    train_data = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "    train_data['quality'] = y_train\n",
    "    centroids = train_data.groupby('quality').mean()\n",
    "    \n",
    "    # Validar en el conjunto de prueba\n",
    "    for i, test_point in enumerate(X_test):\n",
    "        predicted_class = classify_min_distance(test_point, centroids)\n",
    "        y_pred_kfold.append(predicted_class)\n",
    "        if predicted_class == y_test[i]:\n",
    "            correct_predictions_kfold += 1\n",
    "    \n",
    "    # Actualizar el conteo de muestras de prueba\n",
    "    total_test_samples += len(X_test)\n",
    "\n",
    "# Calcular y mostrar la precisión de 10-Fold Cross-Validation\n",
    "accuracy_kfold = correct_predictions_kfold / total_test_samples\n",
    "print(f\"Precisión de 10-Fold Cross-Validation Estratificado: {accuracy_kfold:.2f}\")\n",
    "\n",
    "# Imprimir la matriz de confusión para 10-Fold Cross-Validation\n",
    "print(\"Matriz de Confusión 10-Fold Cross-Validation:\")\n",
    "print(confusion_matrix(y, y_pred_kfold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "K-means-clustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
