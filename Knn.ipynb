{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# This is a subset of the original data available at kaggle.\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Polar\\\\Documents\\\\ESCUELA\\\\5TO_SEMESTRE\\\\MAKINITAS\\\\practica6\\\\winequality\\\\winequality-white.csv\", delimiter=\";\")\n",
    "\n",
    "data.head()\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Leave-One-Out Cross-Validation: 0.51\n",
      "Matriz de Confusión Leave-One-Out:\n",
      "[[   0    2    8    9    1    0    0]\n",
      " [   1   11   66   71   13    1    0]\n",
      " [   1   21  717  598  113    7    0]\n",
      " [   0   18  485 1362  290   43    0]\n",
      " [   0    1   98  370  396   15    0]\n",
      " [   0    0   16   73   51   35    0]\n",
      " [   0    0    0    5    0    0    0]]\n",
      "Precisión de Hold-Out Validation (70-30): 0.48\n",
      "Matriz de Confusión Hold-Out:\n",
      "[[  0   0   3   3   1   0]\n",
      " [  1   5  20  11   3   0]\n",
      " [  1   6 203 181  33   2]\n",
      " [  0   9 166 389  98   6]\n",
      " [  0   2  37 128 104   9]\n",
      " [  0   0   2  26  11  10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\K-means-clustering\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de 10-Fold Cross-Validation Estratificado: 0.50\n",
      "Matriz de Confusión 10-Fold Cross-Validation:\n",
      "[[   0    0    7    8    5    0    0]\n",
      " [   0    2   46   90   22    3    0]\n",
      " [   0   23  425  724  256   29    0]\n",
      " [   2   16  623 1127  384   46    0]\n",
      " [   1    7  248  441  167   16    0]\n",
      " [   0    0   49   85   36    5    0]\n",
      " [   0    1    0    3    1    0    0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# Codificar la columna 'class' como valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "data['quality'] = label_encoder.fit_transform(data['quality'])\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = data.drop(columns=['quality']).values\n",
    "y = data['quality'].values\n",
    "\n",
    "# Función para calcular la distancia Euclidiana\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Función para clasificar un nuevo punto usando el clasificador K-NN\n",
    "def classify_knn(new_point, X_train, y_train, k=1):\n",
    "    distances = []\n",
    "    \n",
    "    # Calcular la distancia entre el nuevo punto y todos los puntos de entrenamiento\n",
    "    for i in range(len(X_train)):\n",
    "        distance = euclidean_distance(new_point, X_train[i])\n",
    "        distances.append((distance, y_train[i]))\n",
    "    \n",
    "    # Ordenar las distancias y seleccionar las k más cercanas\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    k_nearest_classes = [distances[i][1] for i in range(k)]\n",
    "    \n",
    "    # Retornar la clase más común entre los k vecinos\n",
    "    most_common_class = Counter(k_nearest_classes).most_common(1)[0][0]\n",
    "    return most_common_class\n",
    "\n",
    "# --- Leave-One-Out Cross-Validation ---\n",
    "loo = LeaveOneOut()\n",
    "correct_predictions_loo = 0\n",
    "y_pred_loo = []\n",
    "k = int(input(\"Seleccione el valor de k para Leave-One-Out Cross-Validation: \"))\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    predicted_class = classify_knn(X_test[0], X_train, y_train, k=k)\n",
    "    y_pred_loo.append(predicted_class)\n",
    "    \n",
    "    if predicted_class == y_test[0]:\n",
    "        correct_predictions_loo += 1\n",
    "\n",
    "accuracy_loo = correct_predictions_loo / len(X)\n",
    "print(f\"Precisión de Leave-One-Out Cross-Validation: {accuracy_loo:.2f}\")\n",
    "print(\"Matriz de Confusión Leave-One-Out:\")\n",
    "print(confusion_matrix(y, y_pred_loo))\n",
    "\n",
    "# --- Hold-Out Validation (70-30 split) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "k = int(input(\"Seleccione el valor de k para Hold-Out Validation: \"))\n",
    "\n",
    "correct_predictions_holdout = 0\n",
    "y_pred_holdout = []\n",
    "\n",
    "for i, test_point in enumerate(X_test):\n",
    "    predicted_class = classify_knn(test_point, X_train, y_train, k=k)\n",
    "    y_pred_holdout.append(predicted_class)\n",
    "    if predicted_class == y_test[i]:\n",
    "        correct_predictions_holdout += 1\n",
    "\n",
    "accuracy_holdout = correct_predictions_holdout / len(X_test)\n",
    "print(f\"Precisión de Hold-Out Validation (70-30): {accuracy_holdout:.2f}\")\n",
    "print(\"Matriz de Confusión Hold-Out:\")\n",
    "print(confusion_matrix(y_test, y_pred_holdout))\n",
    "\n",
    "# --- 10-Fold Cross-Validation Estratificado ---\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "correct_predictions_kfold = 0\n",
    "total_test_samples = 0\n",
    "y_pred_kfold = []\n",
    "k = int(input(\"Seleccione el valor de k para 10-Fold Cross-Validation: \"))\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    for i, test_point in enumerate(X_test):\n",
    "        predicted_class = classify_knn(test_point, X_train, y_train, k=k)\n",
    "        y_pred_kfold.append(predicted_class)\n",
    "        if predicted_class == y_test[i]:\n",
    "            correct_predictions_kfold += 1\n",
    "    \n",
    "    total_test_samples += len(X_test)\n",
    "\n",
    "accuracy_kfold = correct_predictions_kfold / total_test_samples\n",
    "print(f\"Precisión de 10-Fold Cross-Validation Estratificado: {accuracy_kfold:.2f}\")\n",
    "print(\"Matriz de Confusión 10-Fold Cross-Validation:\")\n",
    "print(confusion_matrix(y, y_pred_kfold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# This is a subset of the original data available at kaggle.\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Polar\\\\Documents\\\\ESCUELA\\\\5TO_SEMESTRE\\\\MAKINITAS\\\\practica6\\\\winequality\\\\winequality-red.csv\", delimiter=\";\")\n",
    "\n",
    "data.head()\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Leave-One-Out Cross-Validation: 0.52\n",
      "Matriz de Confusión Leave-One-Out:\n",
      "[[  0   0   6   2   2   0]\n",
      " [  0   0  32  17   4   0]\n",
      " [  0   1 445 212  23   0]\n",
      " [  0   3 257 313  62   3]\n",
      " [  0   2  32  93  71   1]\n",
      " [  0   0   3   9   6   0]]\n",
      "Precisión de Hold-Out Validation (70-30): 0.49\n",
      "Matriz de Confusión Hold-Out:\n",
      "[[  0   0   1   0   0   0]\n",
      " [  0   0   6  10   1   0]\n",
      " [  0   1 114  70  10   0]\n",
      " [  0   1  77 105  17   0]\n",
      " [  0   0  10  35  16   0]\n",
      " [  0   0   1   4   1   0]]\n",
      "Precisión de 10-Fold Cross-Validation Estratificado: 0.52\n",
      "Matriz de Confusión 10-Fold Cross-Validation:\n",
      "[[  0   0   3   5   2   0]\n",
      " [  0   0  23  24   5   1]\n",
      " [  0   2 323 291  64   1]\n",
      " [  0   3 314 259  59   3]\n",
      " [  0   0 105  77  17   0]\n",
      " [  0   0   9   8   1   0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# Codificar la columna 'class' como valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "data['quality'] = label_encoder.fit_transform(data['quality'])\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = data.drop(columns=['quality']).values\n",
    "y = data['quality'].values\n",
    "\n",
    "# Función para calcular la distancia Euclidiana\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Función para clasificar un nuevo punto usando el clasificador K-NN\n",
    "def classify_knn(new_point, X_train, y_train, k=1):\n",
    "    distances = []\n",
    "    \n",
    "    # Calcular la distancia entre el nuevo punto y todos los puntos de entrenamiento\n",
    "    for i in range(len(X_train)):\n",
    "        distance = euclidean_distance(new_point, X_train[i])\n",
    "        distances.append((distance, y_train[i]))\n",
    "    \n",
    "    # Ordenar las distancias y seleccionar las k más cercanas\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    k_nearest_classes = [distances[i][1] for i in range(k)]\n",
    "    \n",
    "    # Retornar la clase más común entre los k vecinos\n",
    "    most_common_class = Counter(k_nearest_classes).most_common(1)[0][0]\n",
    "    return most_common_class\n",
    "\n",
    "# --- Leave-One-Out Cross-Validation ---\n",
    "loo = LeaveOneOut()\n",
    "correct_predictions_loo = 0\n",
    "y_pred_loo = []\n",
    "k = int(input(\"Seleccione el valor de k para Leave-One-Out Cross-Validation: \"))\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    predicted_class = classify_knn(X_test[0], X_train, y_train, k=k)\n",
    "    y_pred_loo.append(predicted_class)\n",
    "    \n",
    "    if predicted_class == y_test[0]:\n",
    "        correct_predictions_loo += 1\n",
    "\n",
    "accuracy_loo = correct_predictions_loo / len(X)\n",
    "print(f\"Precisión de Leave-One-Out Cross-Validation: {accuracy_loo:.2f}\")\n",
    "print(\"Matriz de Confusión Leave-One-Out:\")\n",
    "print(confusion_matrix(y, y_pred_loo))\n",
    "\n",
    "# --- Hold-Out Validation (70-30 split) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "k = int(input(\"Seleccione el valor de k para Hold-Out Validation: \"))\n",
    "\n",
    "correct_predictions_holdout = 0\n",
    "y_pred_holdout = []\n",
    "\n",
    "for i, test_point in enumerate(X_test):\n",
    "    predicted_class = classify_knn(test_point, X_train, y_train, k=k)\n",
    "    y_pred_holdout.append(predicted_class)\n",
    "    if predicted_class == y_test[i]:\n",
    "        correct_predictions_holdout += 1\n",
    "\n",
    "accuracy_holdout = correct_predictions_holdout / len(X_test)\n",
    "print(f\"Precisión de Hold-Out Validation (70-30): {accuracy_holdout:.2f}\")\n",
    "print(\"Matriz de Confusión Hold-Out:\")\n",
    "print(confusion_matrix(y_test, y_pred_holdout))\n",
    "\n",
    "# --- 10-Fold Cross-Validation Estratificado ---\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "correct_predictions_kfold = 0\n",
    "total_test_samples = 0\n",
    "y_pred_kfold = []\n",
    "k = int(input(\"Seleccione el valor de k para 10-Fold Cross-Validation: \"))\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    for i, test_point in enumerate(X_test):\n",
    "        predicted_class = classify_knn(test_point, X_train, y_train, k=k)\n",
    "        y_pred_kfold.append(predicted_class)\n",
    "        if predicted_class == y_test[i]:\n",
    "            correct_predictions_kfold += 1\n",
    "    \n",
    "    total_test_samples += len(X_test)\n",
    "\n",
    "accuracy_kfold = correct_predictions_kfold / total_test_samples\n",
    "print(f\"Precisión de 10-Fold Cross-Validation Estratificado: {accuracy_kfold:.2f}\")\n",
    "print(\"Matriz de Confusión 10-Fold Cross-Validation:\")\n",
    "print(confusion_matrix(y, y_pred_kfold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Polar\\\\Documents\\\\ESCUELA\\\\5TO_SEMESTRE\\\\MAKINITAS\\\\practica6\\\\iris\\\\iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Leave-One-Out Cross-Validation: 0.97\n",
      "Matriz de Confusión Leave-One-Out:\n",
      "[[50  0  0]\n",
      " [ 0 48  2]\n",
      " [ 0  2 48]]\n",
      "Precisión de Hold-Out Validation (70-30): 1.00\n",
      "Matriz de Confusión Hold-Out:\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Precisión de 10-Fold Cross-Validation Estratificado: 0.96\n",
      "Matriz de Confusión 10-Fold Cross-Validation:\n",
      "[[20 15 15]\n",
      " [15 20 15]\n",
      " [15 15 20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# Codificar la columna 'class' como valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "data['class'] = label_encoder.fit_transform(data['class'])\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = data.drop(columns=['class']).values\n",
    "y = data['class'].values\n",
    "\n",
    "# Función para calcular la distancia Euclidiana\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Función para clasificar un nuevo punto usando el clasificador K-NN\n",
    "def classify_knn(new_point, X_train, y_train, k=1):\n",
    "    distances = []\n",
    "    \n",
    "    # Calcular la distancia entre el nuevo punto y todos los puntos de entrenamiento\n",
    "    for i in range(len(X_train)):\n",
    "        distance = euclidean_distance(new_point, X_train[i])\n",
    "        distances.append((distance, y_train[i]))\n",
    "    \n",
    "    # Ordenar las distancias y seleccionar las k más cercanas\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    k_nearest_classes = [distances[i][1] for i in range(k)]\n",
    "    \n",
    "    # Retornar la clase más común entre los k vecinos\n",
    "    most_common_class = Counter(k_nearest_classes).most_common(1)[0][0]\n",
    "    return most_common_class\n",
    "\n",
    "# --- Leave-One-Out Cross-Validation ---\n",
    "loo = LeaveOneOut()\n",
    "correct_predictions_loo = 0\n",
    "y_pred_loo = []\n",
    "k = int(input(\"Seleccione el valor de k para Leave-One-Out Cross-Validation: \"))\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    predicted_class = classify_knn(X_test[0], X_train, y_train, k=k)\n",
    "    y_pred_loo.append(predicted_class)\n",
    "    \n",
    "    if predicted_class == y_test[0]:\n",
    "        correct_predictions_loo += 1\n",
    "\n",
    "accuracy_loo = correct_predictions_loo / len(X)\n",
    "print(f\"Precisión de Leave-One-Out Cross-Validation: {accuracy_loo:.2f}\")\n",
    "print(\"Matriz de Confusión Leave-One-Out:\")\n",
    "print(confusion_matrix(y, y_pred_loo))\n",
    "\n",
    "# --- Hold-Out Validation (70-30 split) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "k = int(input(\"Seleccione el valor de k para Hold-Out Validation: \"))\n",
    "\n",
    "correct_predictions_holdout = 0\n",
    "y_pred_holdout = []\n",
    "\n",
    "for i, test_point in enumerate(X_test):\n",
    "    predicted_class = classify_knn(test_point, X_train, y_train, k=k)\n",
    "    y_pred_holdout.append(predicted_class)\n",
    "    if predicted_class == y_test[i]:\n",
    "        correct_predictions_holdout += 1\n",
    "\n",
    "accuracy_holdout = correct_predictions_holdout / len(X_test)\n",
    "print(f\"Precisión de Hold-Out Validation (70-30): {accuracy_holdout:.2f}\")\n",
    "print(\"Matriz de Confusión Hold-Out:\")\n",
    "print(confusion_matrix(y_test, y_pred_holdout))\n",
    "\n",
    "# --- 10-Fold Cross-Validation Estratificado ---\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "correct_predictions_kfold = 0\n",
    "total_test_samples = 0\n",
    "y_pred_kfold = []\n",
    "k = int(input(\"Seleccione el valor de k para 10-Fold Cross-Validation: \"))\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    for i, test_point in enumerate(X_test):\n",
    "        predicted_class = classify_knn(test_point, X_train, y_train, k=k)\n",
    "        y_pred_kfold.append(predicted_class)\n",
    "        if predicted_class == y_test[i]:\n",
    "            correct_predictions_kfold += 1\n",
    "    \n",
    "    total_test_samples += len(X_test)\n",
    "\n",
    "accuracy_kfold = correct_predictions_kfold / total_test_samples\n",
    "print(f\"Precisión de 10-Fold Cross-Validation Estratificado: {accuracy_kfold:.2f}\")\n",
    "print(\"Matriz de Confusión 10-Fold Cross-Validation:\")\n",
    "print(confusion_matrix(y, y_pred_kfold))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "K-means-clustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
